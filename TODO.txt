TODO:
- implement scenarios. first run them by hand. start from simple single step and continue with more complex:
     - adding task (1 step)
         - "can you add task a and b to my homework list?" âœ…
     - listing tasks (1 step)
         - "can you list my items in games wish list?" âœ…
     - moving tasks to new context (1 step)
         - "can you move the items in study context to homework context?" âœ…
     - modifying task attributes (2 step)
         - "can you change the name of elden ring to elden lord?"
     - removing context (1 step)
         - "can you remove my study list?"
     - removing task (2 steps) âœ…
         - 'can you remove "bananas" and "rust" from my items?'
         - NOTE: not mentioning names in "" leads to error.
     - merging contexts (2 steps)
         - "can you merge best games context and games wish list context?"
     - adding deadline, start, period or any sort of time (2 step)
         - "can you add a deadline for my study list for tomorrow?"
     - mark task as done (2 steps)
         - "can you mark elden ring from my games wish list as done?"
 - find a task by name âœ…
 - read https://github.com/MeetKai/functionary, https://www.reddit.com/r/LocalLLaMA/comments/194z9l6/strategies_for_personal_assistant_function_calling/, https://learn.deeplearning.ai/courses/prompt-engineering-with-llama-2/lesson/1/introduction
 - json won't parse if a character is extra or missing. make it robust.
 - more robust way to map llm func params to actual func params. use string diff. Some libraries are already doing this âœ…ðŸ¤”
 - tune model:
     - tune tempereture. Start with 0 temperature
 - Frontend: use streamlit

Helper functions:
 -
 
Notes:
 - spell checking. may need to first find the correct task title and id.
 - may be good to store the last n characters of the conversation and input it as context to the model.
 - best way for remote function calling in python
 - model may perform repetitive operations. when asked to merge, it added some tasks first which is wrong.
 - can pass history in each request to enrich the propmt.
 - can pass the output of todo --flat in each request to enrich the promp.
 - can let the model hallucinate to see other scenarios and test cases and the model's response
 - can specify the steps the model needs to take to respond for each specific query and command
 - as mentioned in OpenAI's website: Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.

Questions:
 - design a feedback loop. how the model is meant to know the meaning of errors?