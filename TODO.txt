TODO:
    - deadline: 22 Apr, 5pm. prepare a timetable, demonstrating timing of different phases, like API implementation, RAG, documentation.
    - implement scenarios. first run them by hand. start from simple single step and continue with more complex:
        - adding task (1 step) âœ…
        - listing tasks (1 step) âœ…
        - moving tasks to new context (1 step) âœ…
        - modifying task attributes (2 step) âœ…
        - removing task (2 steps) âœ…
            - NOTE: not mentioning names in "" leads to error.
        - mark task as done (2 steps) âœ…
        - removing context (1 step)
            - can you remove my study list?
        - merging contexts (2 steps)
            - can y ou merge best games context and games wish list context?
        - adding deadline, start, period or any sort of time (2 step)
            - can you add a deadline for my study list for tomorrow?
    - ask the user before carrying out the operation if there is an operation.
    - read https://github.com/MeetKai/functionary, https://www.reddit.com/r/LocalLLaMA/comments/194z9l6/strategies_for_personal_assistant_function_calling/, https://learn.deeplearning.ai/courses/prompt-engineering-with-llama-2/lesson/1/introduction
    - more robust way to map llm func params to actual func params. use string diff. Some libraries are already doing this âœ…ðŸ¤”
    - tune tempereture. Start with 0 temperature
    - prevent from responding to irrelevant requests
    - Frontend: use streamlit
  
Notes:
 - LLM is not consistant with finding tasks' ids, maybe it's better to always use the task names. In this case repetitive task names may be problematic.
 - spell checking. may need to first find the correct task title and id.
 - may be good to store the last n characters of the conversation and input it as context to the model.
 - model may perform repetitive operations. when asked to merge, it added some tasks first which is wrong.
 - can let the model hallucinate to see other scenarios and test cases and the model's response
 - can specify the steps the model needs to take to respond for each specific query and command
 - as mentioned in OpenAI's website: Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.

Questions:
 - design a feedback loop. how the model is meant to know the meaning of errors?